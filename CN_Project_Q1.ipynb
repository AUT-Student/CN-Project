{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AUT-Student/CN-Project/blob/main/CN_Project_Q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><b>In the name of God</b></center>\n",
        "\n",
        "<b>Course</b>: Complex Network\n",
        "<br>\n",
        "<b>Description:</b> Final Project | Question 1\n",
        "<br>\n",
        "<b>Developer</b>: Alireza Mazochi (400131075)"
      ],
      "metadata": {
        "id": "dbsXgbwc34TT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "cb__SSZSsooQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_eFYCPpsYEh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.nn import Linear, ReLU\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "18zUntL68PqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uE-LvmdB8baR",
        "outputId": "8208efd5-4f46-48e9-a93a-b9ee7f08dc30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
        "!pip install torch-geometric\n",
        "!pip install torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-1.13.0+cu116.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wRi13M887k7O",
        "outputId": "cb7bbe25-0e0d-475c-a275-4cd7ff3f8eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting pyg-lib\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/pyg_lib-0.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.16%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-scatter, pyg-lib, torch-sparse\n",
            "Successfully installed pyg-lib-0.1.0+pt113cu116 torch-scatter-2.1.0+pt113cu116 torch-sparse-0.6.16+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.25.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (4.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=007fb786dbad620b49f9c21cbeb5547124da28fbc12caa0cc5a6b0323623f14a\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: psutil, torch-geometric\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 torch-geometric-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_cluster-1.6.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_spline_conv-1.2.1%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (873 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m873.9/873.9 KB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-cluster) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-cluster) (1.21.6)\n",
            "Installing collected packages: torch-spline-conv, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0+pt113cu116 torch-spline-conv-1.2.1+pt113cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric"
      ],
      "metadata": {
        "id": "IibwB8xc9fbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "VIbw3edf8SFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load"
      ],
      "metadata": {
        "id": "oEWPcrC8hVwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets.planetoid import Planetoid"
      ],
      "metadata": {
        "id": "055dYQgS5pkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "planetoid = Planetoid(\"/content/planetoid\", name=\"PubMed\")"
      ],
      "metadata": {
        "id": "OSBf7H6K6V2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c734d6a-afe6-49d7-cf1d-895dfda6efac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = planetoid[0]"
      ],
      "metadata": {
        "id": "s1zhgkCs6nCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "Lnj0pgmRhYFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa-MnxuZ88ge",
        "outputId": "3b7f0826-95a5-4d6a-d0fb-3b2436df7d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[19717, 500], edge_index=[2, 88648], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(dataset[\"y\"].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1RBCVns8-Mf",
        "outputId": "86460d7d-ddee-4fbb-8943-601a775c0320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.num_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBHayla99Kb2",
        "outputId": "bfe79f06-4d48-4594-cd10-df064bb0191b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.num_edge_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihLESSeT9NO1",
        "outputId": "0cd08720-0683-47eb-beb1-5f7c735a47d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(sum(dataset.train_mask), sum(dataset.val_mask), sum(dataset.test_mask))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az8Fif_f9cb1",
        "outputId": "d1c49fa7-57ae-4d08-f22e-389bc80b147b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(60), tensor(500), tensor(1000))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Test"
      ],
      "metadata": {
        "id": "2WeABDYaBXPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=1, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.min_validation_loss = np.inf\n",
        "\n",
        "    def early_stop(self, validation_loss):\n",
        "        if validation_loss < self.min_validation_loss:\n",
        "            self.min_validation_loss = validation_loss\n",
        "            self.counter = 0\n",
        "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False"
      ],
      "metadata": {
        "id": "so6PaUkQj8Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model):\n",
        "  model.train()\n",
        "\n",
        "  early_stopper = EarlyStopper(patience=3, min_delta=0.01)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "  for epoch in range(2000):\n",
        "    pred = model(dataset.x, dataset.edge_index)\n",
        "    train_loss = F.cross_entropy(pred[dataset.train_mask],\n",
        "                                  dataset.y[dataset.train_mask])\n",
        "    \n",
        "    validation_loss = F.cross_entropy(pred[dataset.val_mask],\n",
        "                                      dataset.y[dataset.val_mask])\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if early_stopper.early_stop(validation_loss):             \n",
        "        break"
      ],
      "metadata": {
        "id": "KWPFjPzHAoQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_test(model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    pred = model(dataset.x, dataset.edge_index).argmax(dim=-1)\n",
        "\n",
        "  accs = []\n",
        "  for mask in [dataset.train_mask, dataset.val_mask, dataset.test_mask]:\n",
        "      accs.append(int((pred[mask] == dataset.y[mask]).sum()) / int(mask.sum()))\n",
        "\n",
        "  print(f\"Train Accuracy = {accs[0]}\")\n",
        "  print(f\"Valid Accuracy = {accs[1]}\")\n",
        "  print(f\"Test  Accuracy = {accs[2]}\")"
      ],
      "metadata": {
        "id": "uPOwvB0nGLKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    pred = model(dataset.x, dataset.edge_index).argmax(dim=-1)\n",
        "\n",
        "\n",
        "  return int((pred[dataset.test_mask] == dataset.y[dataset.test_mask]).sum()) / int(dataset.test_mask.sum())"
      ],
      "metadata": {
        "id": "zyzvvmW0rFT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "WTNjv_bmBtOX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN"
      ],
      "metadata": {
        "id": "_OwTbqoiFmc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, dimentions, number_gcn, number_fc):\n",
        "        super().__init__()\n",
        "        assert(len(dimentions) == number_gcn+number_fc+1)\n",
        "        self.number_gcn = number_gcn\n",
        "        self.number_fc = number_fc\n",
        "        self.layers_gcn = []\n",
        "        self.layers_fc = []\n",
        "\n",
        "        for in_dim, out_dim in zip(dimentions[:number_gcn],\n",
        "                                   dimentions[1:number_gcn+1]):\n",
        "          \n",
        "          self.layers_gcn.append(GCNConv(in_dim, out_dim))\n",
        "          \n",
        "        self.layers_gcn = torch.nn.ModuleList(self.layers_gcn)\n",
        "        \n",
        "        for in_dim, out_dim in zip(dimentions[number_gcn:],\n",
        "                                   dimentions[number_gcn+1:]):\n",
        "          \n",
        "          self.layers_fc.append(Linear(in_dim, out_dim))\n",
        "        \n",
        "        self.layers_fc = torch.nn.ModuleList(self.layers_fc)\n",
        "        \n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
        "        for i in range(self.number_gcn):\n",
        "          x = self.layers_gcn[i](x, edge_index).relu()\n",
        "\n",
        "        for i in range(self.number_fc):\n",
        "          x = self.layers_fc[i](x).sigmoid()\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "lxDlbNCOFpr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAT"
      ],
      "metadata": {
        "id": "I8MLzopqYfPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Source: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gat.py\n",
        "\n",
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(in_channels, hidden_channels[0], heads,\n",
        "                             concat=False, dropout=0.3)\n",
        "        self.conv2 = GATConv(hidden_channels[0], hidden_channels[1], heads=1,\n",
        "                             concat=False, dropout=0.3)\n",
        "        self.conv3 = GATConv(hidden_channels[1], out_channels, heads=1,\n",
        "                             concat=False, dropout=0.3)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = F.elu(self.conv2(x, edge_index))\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "0kn27p1KYgYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAT Dynamic Weight"
      ],
      "metadata": {
        "id": "Q0BcGs8LCyET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Source: https://github.com/pyg-team/pytorch_geometric/blob/master/torch_geometric/nn/conv/gat_conv.py\n",
        "\n",
        "from typing import Optional, Tuple, Union\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from torch.nn import Parameter\n",
        "\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.nn.dense.linear import Linear\n",
        "from torch_geometric.typing import NoneType  # noqa\n",
        "from torch_geometric.typing import (\n",
        "    Adj,\n",
        "    OptPairTensor,\n",
        "    OptTensor,\n",
        "    Size,\n",
        "    SparseTensor,\n",
        ")\n",
        "\n",
        "import torch_sparse\n",
        "\n",
        "from torch_geometric.utils import add_self_loops, remove_self_loops, softmax\n",
        "\n",
        "from torch_geometric.nn.inits import glorot, zeros\n",
        "\n",
        "class GATConvDynamicWeights(MessagePassing):\n",
        "    r\"\"\"The graph attentional operator from the `\"Graph Attention Networks\"\n",
        "    <https://arxiv.org/abs/1710.10903>`_ paper\n",
        "\n",
        "    .. math::\n",
        "        \\mathbf{x}^{\\prime}_i = \\alpha_{i,i}\\mathbf{\\Theta}\\mathbf{x}_{i} +\n",
        "        \\sum_{j \\in \\mathcal{N}(i)} \\alpha_{i,j}\\mathbf{\\Theta}\\mathbf{x}_{j},\n",
        "\n",
        "    where the attention coefficients :math:`\\alpha_{i,j}` are computed as\n",
        "\n",
        "    .. math::\n",
        "        \\alpha_{i,j} =\n",
        "        \\frac{\n",
        "        \\exp\\left(\\mathrm{LeakyReLU}\\left(\\mathbf{a}^{\\top}\n",
        "        [\\mathbf{\\Theta}\\mathbf{x}_i \\, \\Vert \\, \\mathbf{\\Theta}\\mathbf{x}_j]\n",
        "        \\right)\\right)}\n",
        "        {\\sum_{k \\in \\mathcal{N}(i) \\cup \\{ i \\}}\n",
        "        \\exp\\left(\\mathrm{LeakyReLU}\\left(\\mathbf{a}^{\\top}\n",
        "        [\\mathbf{\\Theta}\\mathbf{x}_i \\, \\Vert \\, \\mathbf{\\Theta}\\mathbf{x}_k]\n",
        "        \\right)\\right)}.\n",
        "\n",
        "    If the graph has multi-dimensional edge features :math:`\\mathbf{e}_{i,j}`,\n",
        "    the attention coefficients :math:`\\alpha_{i,j}` are computed as\n",
        "\n",
        "    .. math::\n",
        "        \\alpha_{i,j} =\n",
        "        \\frac{\n",
        "        \\exp\\left(\\mathrm{LeakyReLU}\\left(\\mathbf{a}^{\\top}\n",
        "        [\\mathbf{\\Theta}\\mathbf{x}_i \\, \\Vert \\, \\mathbf{\\Theta}\\mathbf{x}_j\n",
        "        \\, \\Vert \\, \\mathbf{\\Theta}_{e} \\mathbf{e}_{i,j}]\\right)\\right)}\n",
        "        {\\sum_{k \\in \\mathcal{N}(i) \\cup \\{ i \\}}\n",
        "        \\exp\\left(\\mathrm{LeakyReLU}\\left(\\mathbf{a}^{\\top}\n",
        "        [\\mathbf{\\Theta}\\mathbf{x}_i \\, \\Vert \\, \\mathbf{\\Theta}\\mathbf{x}_k\n",
        "        \\, \\Vert \\, \\mathbf{\\Theta}_{e} \\mathbf{e}_{i,k}]\\right)\\right)}.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int or tuple): Size of each input sample, or :obj:`-1` to\n",
        "            derive the size from the first input(s) to the forward method.\n",
        "            A tuple corresponds to the sizes of source and target\n",
        "            dimensionalities.\n",
        "        out_channels (int): Size of each output sample.\n",
        "        heads (int, optional): Number of multi-head-attentions.\n",
        "            (default: :obj:`1`)\n",
        "        concat (bool, optional): <REMOVED by me> If set to :obj:`False`, the multi-head\n",
        "            attentions are averaged instead of concatenated.\n",
        "            (default: :obj:`True`)\n",
        "        negative_slope (float, optional): LeakyReLU angle of the negative\n",
        "            slope. (default: :obj:`0.2`)\n",
        "        dropout (float, optional): Dropout probability of the normalized\n",
        "            attention coefficients which exposes each node to a stochastically\n",
        "            sampled neighborhood during training. (default: :obj:`0`)\n",
        "        add_self_loops (bool, optional): If set to :obj:`False`, will not add\n",
        "            self-loops to the input graph. (default: :obj:`True`)\n",
        "        edge_dim (int, optional): Edge feature dimensionality (in case\n",
        "            there are any). (default: :obj:`None`)\n",
        "        fill_value (float or Tensor or str, optional): The way to generate\n",
        "            edge features of self-loops (in case :obj:`edge_dim != None`).\n",
        "            If given as :obj:`float` or :class:`torch.Tensor`, edge features of\n",
        "            self-loops will be directly given by :obj:`fill_value`.\n",
        "            If given as :obj:`str`, edge features of self-loops are computed by\n",
        "            aggregating all features of edges that point to the specific node,\n",
        "            according to a reduce operation. (:obj:`\"add\"`, :obj:`\"mean\"`,\n",
        "            :obj:`\"min\"`, :obj:`\"max\"`, :obj:`\"mul\"`). (default: :obj:`\"mean\"`)\n",
        "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
        "            an additive bias. (default: :obj:`True`)\n",
        "        **kwargs (optional): Additional arguments of\n",
        "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
        "\n",
        "    Shapes:\n",
        "        - **input:**\n",
        "          node features :math:`(|\\mathcal{V}|, F_{in})` or\n",
        "          :math:`((|\\mathcal{V_s}|, F_{s}), (|\\mathcal{V_t}|, F_{t}))`\n",
        "          if bipartite,\n",
        "          edge indices :math:`(2, |\\mathcal{E}|)`,\n",
        "          edge features :math:`(|\\mathcal{E}|, D)` *(optional)*\n",
        "        - **output:** node features :math:`(|\\mathcal{V}|, H * F_{out})` or\n",
        "          :math:`((|\\mathcal{V}_t|, H * F_{out})` if bipartite.\n",
        "          If :obj:`return_attention_weights=True`, then\n",
        "          :math:`((|\\mathcal{V}|, H * F_{out}),\n",
        "          ((2, |\\mathcal{E}|), (|\\mathcal{E}|, H)))`\n",
        "          or :math:`((|\\mathcal{V_t}|, H * F_{out}), ((2, |\\mathcal{E}|),\n",
        "          (|\\mathcal{E}|, H)))` if bipartite\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: Union[int, Tuple[int, int]],\n",
        "        out_channels: int,\n",
        "        heads: int = 1,\n",
        "        negative_slope: float = 0.2,\n",
        "        dropout: float = 0.0,\n",
        "        add_self_loops: bool = True,\n",
        "        edge_dim: Optional[int] = None,\n",
        "        fill_value: Union[float, Tensor, str] = 'mean',\n",
        "        bias: bool = True,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.heads = heads\n",
        "        # Changed Code:\n",
        "        concat = False\n",
        "        self.concat = concat\n",
        "        \n",
        "        self.negative_slope = negative_slope\n",
        "        self.dropout = dropout\n",
        "        self.add_self_loops = add_self_loops\n",
        "        self.edge_dim = edge_dim\n",
        "        self.fill_value = fill_value\n",
        "\n",
        "        # In case we are operating in bipartite graphs, we apply separate\n",
        "        # transformations 'lin_src' and 'lin_dst' to source and target nodes:\n",
        "        if isinstance(in_channels, int):\n",
        "            self.lin_src = Linear(in_channels, heads * out_channels,\n",
        "                                  bias=False, weight_initializer='glorot')\n",
        "            self.lin_dst = self.lin_src\n",
        "        else:\n",
        "            self.lin_src = Linear(in_channels[0], heads * out_channels, False,\n",
        "                                  weight_initializer='glorot')\n",
        "            self.lin_dst = Linear(in_channels[1], heads * out_channels, False,\n",
        "                                  weight_initializer='glorot')\n",
        "\n",
        "        # The learnable parameters to compute attention coefficients:\n",
        "        self.att_src = Parameter(torch.Tensor(1, heads, out_channels))\n",
        "        self.att_dst = Parameter(torch.Tensor(1, heads, out_channels))\n",
        "\n",
        "        # Changed Code:\n",
        "        self.learnable_average_layer = torch.nn.Conv1d(in_channels=heads,\n",
        "                                                       out_channels=1,\n",
        "                                                       kernel_size=1)\n",
        "\n",
        "\n",
        "        if edge_dim is not None:\n",
        "            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False,\n",
        "                                   weight_initializer='glorot')\n",
        "            self.att_edge = Parameter(torch.Tensor(1, heads, out_channels))\n",
        "        else:\n",
        "            self.lin_edge = None\n",
        "            self.register_parameter('att_edge', None)\n",
        "\n",
        "        if bias and concat:\n",
        "            self.bias = Parameter(torch.Tensor(heads * out_channels))\n",
        "        elif bias and not concat:\n",
        "            self.bias = Parameter(torch.Tensor(out_channels))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # super().reset_parameters()\n",
        "        self.lin_src.reset_parameters()\n",
        "        self.lin_dst.reset_parameters()\n",
        "        if self.lin_edge is not None:\n",
        "            self.lin_edge.reset_parameters()\n",
        "        glorot(self.att_src)\n",
        "        glorot(self.att_dst)\n",
        "        glorot(self.att_edge)\n",
        "        zeros(self.bias)\n",
        "\n",
        "        # Changed Code:\n",
        "        # self.learnable_average_layer.reset_parameters()\n",
        "\n",
        "    def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj,\n",
        "                edge_attr: OptTensor = None, size: Size = None,\n",
        "                return_attention_weights=None):\n",
        "        # type: (Union[Tensor, OptPairTensor], Tensor, OptTensor, Size, NoneType) -> Tensor  # noqa\n",
        "        # type: (Union[Tensor, OptPairTensor], SparseTensor, OptTensor, Size, NoneType) -> Tensor  # noqa\n",
        "        # type: (Union[Tensor, OptPairTensor], Tensor, OptTensor, Size, bool) -> Tuple[Tensor, Tuple[Tensor, Tensor]]  # noqa\n",
        "        # type: (Union[Tensor, OptPairTensor], SparseTensor, OptTensor, Size, bool) -> Tuple[Tensor, SparseTensor]  # noqa\n",
        "        r\"\"\"\n",
        "        Args:\n",
        "            return_attention_weights (bool, optional): If set to :obj:`True`,\n",
        "                will additionally return the tuple\n",
        "                :obj:`(edge_index, attention_weights)`, holding the computed\n",
        "                attention weights for each edge. (default: :obj:`None`)\n",
        "        \"\"\"\n",
        "        # NOTE: attention weights will be returned whenever\n",
        "        # `return_attention_weights` is set to a value, regardless of its\n",
        "        # actual value (might be `True` or `False`). This is a current somewhat\n",
        "        # hacky workaround to allow for TorchScript support via the\n",
        "        # `torch.jit._overload` decorator, as we can only change the output\n",
        "        # arguments conditioned on type (`None` or `bool`), not based on its\n",
        "        # actual value.\n",
        "\n",
        "        H, C = self.heads, self.out_channels\n",
        "\n",
        "        # We first transform the input node features. If a tuple is passed, we\n",
        "        # transform source and target node features via separate weights:\n",
        "        if isinstance(x, Tensor):\n",
        "            assert x.dim() == 2, \"Static graphs not supported in 'GATConv'\"\n",
        "            x_src = x_dst = self.lin_src(x).view(-1, H, C)\n",
        "        else:  # Tuple of source and target node features:\n",
        "            x_src, x_dst = x\n",
        "            assert x_src.dim() == 2, \"Static graphs not supported in 'GATConv'\"\n",
        "            x_src = self.lin_src(x_src).view(-1, H, C)\n",
        "            if x_dst is not None:\n",
        "                x_dst = self.lin_dst(x_dst).view(-1, H, C)\n",
        "\n",
        "        x = (x_src, x_dst)\n",
        "\n",
        "        # Next, we compute node-level attention coefficients, both for source\n",
        "        # and target nodes (if present):\n",
        "        alpha_src = (x_src * self.att_src).sum(dim=-1)\n",
        "        alpha_dst = None if x_dst is None else (x_dst * self.att_dst).sum(-1)\n",
        "        alpha = (alpha_src, alpha_dst)\n",
        "\n",
        "        if self.add_self_loops:\n",
        "            if isinstance(edge_index, Tensor):\n",
        "                # We only want to add self-loops for nodes that appear both as\n",
        "                # source and target nodes:\n",
        "                num_nodes = x_src.size(0)\n",
        "                if x_dst is not None:\n",
        "                    num_nodes = min(num_nodes, x_dst.size(0))\n",
        "                num_nodes = min(size) if size is not None else num_nodes\n",
        "                edge_index, edge_attr = remove_self_loops(\n",
        "                    edge_index, edge_attr)\n",
        "                edge_index, edge_attr = add_self_loops(\n",
        "                    edge_index, edge_attr, fill_value=self.fill_value,\n",
        "                    num_nodes=num_nodes)\n",
        "            elif isinstance(edge_index, SparseTensor):\n",
        "                if self.edge_dim is None:\n",
        "                    edge_index = torch_sparse.set_diag(edge_index)\n",
        "                else:\n",
        "                    raise NotImplementedError(\n",
        "                        \"The usage of 'edge_attr' and 'add_self_loops' \"\n",
        "                        \"simultaneously is currently not yet supported for \"\n",
        "                        \"'edge_index' in a 'SparseTensor' form\")\n",
        "\n",
        "        # edge_updater_type: (alpha: OptPairTensor, edge_attr: OptTensor)\n",
        "        alpha = self.edge_updater(edge_index, alpha=alpha, edge_attr=edge_attr)\n",
        "\n",
        "        # propagate_type: (x: OptPairTensor, alpha: Tensor)\n",
        "        out = self.propagate(edge_index, x=x, alpha=alpha, size=size)\n",
        "\n",
        "        # if self.concat:\n",
        "        #     out = out.view(-1, self.heads * self.out_channels)\n",
        "        # else:\n",
        "        #     out = out.mean(dim=1)\n",
        "\n",
        "        # Changed Code:\n",
        "        # Source: https://stackoverflow.com/a/58574603/8961642\n",
        "        out = self.learnable_average_layer(out)\n",
        "        out = out.squeeze()\n",
        "            \n",
        "        if self.bias is not None:\n",
        "            out = out + self.bias\n",
        "\n",
        "        if isinstance(return_attention_weights, bool):\n",
        "            if isinstance(edge_index, Tensor):\n",
        "                return out, (edge_index, alpha)\n",
        "            elif isinstance(edge_index, SparseTensor):\n",
        "                return out, edge_index.set_value(alpha, layout='coo')\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "    def edge_update(self, alpha_j: Tensor, alpha_i: OptTensor,\n",
        "                    edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n",
        "                    size_i: Optional[int]) -> Tensor:\n",
        "        # Given edge-level attention coefficients for source and target nodes,\n",
        "        # we simply need to sum them up to \"emulate\" concatenation:\n",
        "        alpha = alpha_j if alpha_i is None else alpha_j + alpha_i\n",
        "\n",
        "        if edge_attr is not None and self.lin_edge is not None:\n",
        "            if edge_attr.dim() == 1:\n",
        "                edge_attr = edge_attr.view(-1, 1)\n",
        "            edge_attr = self.lin_edge(edge_attr)\n",
        "            edge_attr = edge_attr.view(-1, self.heads, self.out_channels)\n",
        "            alpha_edge = (edge_attr * self.att_edge).sum(dim=-1)\n",
        "            alpha = alpha + alpha_edge\n",
        "\n",
        "        alpha = F.leaky_relu(alpha, self.negative_slope)\n",
        "        alpha = softmax(alpha, index, ptr, size_i)\n",
        "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
        "        return alpha\n",
        "\n",
        "    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n",
        "        return alpha.unsqueeze(-1) * x_j\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
        "                f'{self.out_channels}, heads={self.heads})')"
      ],
      "metadata": {
        "id": "UFhM3UA6V0rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GATDynamicWeights(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConvDynamicWeights(in_channels, hidden_channels, heads,\n",
        "                             dropout=0.3)\n",
        "\n",
        "        self.conv2 = GATConvDynamicWeights(hidden_channels, out_channels, heads=1,\n",
        "                             dropout=0.3)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "AunaP7sCT40q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAT V2 Message Operation"
      ],
      "metadata": {
        "id": "cizO7OEt9_z7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{equation}\n",
        "\\mathbf{x}^{\\prime}_i = \\alpha_{i,i}\\mathbf{\\Theta}\\mathbf{x}_{i} +\n",
        "\\sum_{j \\in \\mathcal{N}(i)} \\alpha_{i,j}\\mathbf{\\Theta}\\mathbf{x}_{j}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\alpha_{i,j} =\n",
        "        \\frac{\n",
        "        \\exp\\left(\\mathbf{a}^{\\top}\\mathrm{LeakyReLU}\\left(\\mathbf{\\Theta}\n",
        "        [\\mathbf{x}_i \\, \\Vert \\, \\mathbf{x}_j]\n",
        "        \\right)\\right)}\n",
        "        {\\sum_{k \\in \\mathcal{N}(i) \\cup \\{ i \\}}\n",
        "        \\exp\\left(\\mathbf{a}^{\\top}\\mathrm{LeakyReLU}\\left(\\mathbf{\\Theta}\n",
        "        [\\mathbf{x}_i \\, \\Vert \\, \\mathbf{x}_k]\n",
        "        \\right)\\right)}.\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\alpha_{i,j} =\n",
        "        \\frac{\n",
        "        \\exp\\left(\\mathbf{a}^{\\top}\\mathrm{LeakyReLU}\\left(\\mathbf{\\Theta}\n",
        "        [\\mathbf{x}_i \\, \\Vert \\, \\mathbf{x}_j \\, \\Vert \\, \\mathbf{e}_{i,j}]\n",
        "        \\right)\\right)}\n",
        "        {\\sum_{k \\in \\mathcal{N}(i) \\cup \\{ i \\}}\n",
        "        \\exp\\left(\\mathbf{a}^{\\top}\\mathrm{LeakyReLU}\\left(\\mathbf{\\Theta}\n",
        "        [\\mathbf{x}_i \\, \\Vert \\, \\mathbf{x}_k \\, \\Vert \\, \\mathbf{e}_{i,k}]\n",
        "        \\right)\\right)}\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "4TCL6s3-je_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Source: https://github.com/pyg-team/pytorch_geometric/blob/master/torch_geometric/nn/conv/gatv2_conv.py\n",
        "\n",
        "from typing import Optional, Tuple, Union\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from torch.nn import Parameter\n",
        "\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.nn.dense.linear import Linear\n",
        "from torch_geometric.nn.inits import glorot, zeros\n",
        "from torch_geometric.typing import (\n",
        "    Adj,\n",
        "    OptTensor,\n",
        "    PairTensor,\n",
        "    SparseTensor,\n",
        ")\n",
        "import torch_sparse\n",
        "from torch_geometric.utils import add_self_loops, remove_self_loops, softmax\n",
        "\n",
        "class GATv2ConvMessageOperation(MessagePassing):\n",
        "    r\"\"\"The GATv2 operator from the `\"How Attentive are Graph Attention\n",
        "    Networks?\" <https://arxiv.org/abs/2105.14491>`_ paper, which fixes the\n",
        "    static attention problem of the standard\n",
        "    :class:`~torch_geometric.conv.GATConv` layer.\n",
        "    Since the linear layers in the standard GAT are applied right after each\n",
        "    other, the ranking of attended nodes is unconditioned on the query node.\n",
        "    In contrast, in :class:`GATv2`, every node can attend to any other node.\n",
        "    .. math::\n",
        "        \\mathbf{x}^{\\prime}_i = \\alpha_{i,i}\\mathbf{\\Theta}\\mathbf{x}_{i} +\n",
        "        \\sum_{j \\in \\mathcal{N}(i)} \\alpha_{i,j}\\mathbf{\\Theta}\\mathbf{x}_{j},\n",
        "    where the attention coefficients :math:`\\alpha_{i,j}` are computed as\n",
        "    .. math::\n",
        "        \\alpha_{i,j} =\n",
        "        \\frac{\n",
        "        \\exp\\left(\\mathbf{a}^{\\top}\\mathrm{LeakyReLU}\\left(\\mathbf{\\Theta}\n",
        "        [\\mathbf{x}_i \\, \\Vert \\, \\mathbf{x}_j]\n",
        "        \\right)\\right)}\n",
        "        {\\sum_{k \\in \\mathcal{N}(i) \\cup \\{ i \\}}\n",
        "        \\exp\\left(\\mathbf{a}^{\\top}\\mathrm{LeakyReLU}\\left(\\mathbf{\\Theta}\n",
        "        [\\mathbf{x}_i \\, \\Vert \\, \\mathbf{x}_k]\n",
        "        \\right)\\right)}.\n",
        "    If the graph has multi-dimensional edge features :math:`\\mathbf{e}_{i,j}`,\n",
        "    the attention coefficients :math:`\\alpha_{i,j}` are computed as\n",
        "    .. math::\n",
        "        \\alpha_{i,j} =\n",
        "        \\frac{\n",
        "        \\exp\\left(\\mathbf{a}^{\\top}\\mathrm{LeakyReLU}\\left(\\mathbf{\\Theta}\n",
        "        [\\mathbf{x}_i \\, \\Vert \\, \\mathbf{x}_j \\, \\Vert \\, \\mathbf{e}_{i,j}]\n",
        "        \\right)\\right)}\n",
        "        {\\sum_{k \\in \\mathcal{N}(i) \\cup \\{ i \\}}\n",
        "        \\exp\\left(\\mathbf{a}^{\\top}\\mathrm{LeakyReLU}\\left(\\mathbf{\\Theta}\n",
        "        [\\mathbf{x}_i \\, \\Vert \\, \\mathbf{x}_k \\, \\Vert \\, \\mathbf{e}_{i,k}]\n",
        "        \\right)\\right)}.\n",
        "    Args:\n",
        "        in_channels (int or tuple): Size of each input sample, or :obj:`-1` to\n",
        "            derive the size from the first input(s) to the forward method.\n",
        "            A tuple corresponds to the sizes of source and target\n",
        "            dimensionalities.\n",
        "        out_channels (int): Size of each output sample.\n",
        "        heads (int, optional): Number of multi-head-attentions.\n",
        "            (default: :obj:`1`)\n",
        "        concat (bool, optional): If set to :obj:`False`, the multi-head\n",
        "            attentions are averaged instead of concatenated.\n",
        "            (default: :obj:`True`)\n",
        "        negative_slope (float, optional): LeakyReLU angle of the negative\n",
        "            slope. (default: :obj:`0.2`)\n",
        "        dropout (float, optional): Dropout probability of the normalized\n",
        "            attention coefficients which exposes each node to a stochastically\n",
        "            sampled neighborhood during training. (default: :obj:`0`)\n",
        "        add_self_loops (bool, optional): If set to :obj:`False`, will not add\n",
        "            self-loops to the input graph. (default: :obj:`True`)\n",
        "        edge_dim (int, optional): Edge feature dimensionality (in case\n",
        "            there are any). (default: :obj:`None`)\n",
        "        fill_value (float or Tensor or str, optional): The way to generate\n",
        "            edge features of self-loops (in case :obj:`edge_dim != None`).\n",
        "            If given as :obj:`float` or :class:`torch.Tensor`, edge features of\n",
        "            self-loops will be directly given by :obj:`fill_value`.\n",
        "            If given as :obj:`str`, edge features of self-loops are computed by\n",
        "            aggregating all features of edges that point to the specific node,\n",
        "            according to a reduce operation. (:obj:`\"add\"`, :obj:`\"mean\"`,\n",
        "            :obj:`\"min\"`, :obj:`\"max\"`, :obj:`\"mul\"`). (default: :obj:`\"mean\"`)\n",
        "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
        "            an additive bias. (default: :obj:`True`)\n",
        "        share_weights (bool, optional): If set to :obj:`True`, the same matrix\n",
        "            will be applied to the source and the target node of every edge.\n",
        "            (default: :obj:`False`)\n",
        "        **kwargs (optional): Additional arguments of\n",
        "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
        "    Shapes:\n",
        "        - **input:**\n",
        "          node features :math:`(|\\mathcal{V}|, F_{in})` or\n",
        "          :math:`((|\\mathcal{V_s}|, F_{s}), (|\\mathcal{V_t}|, F_{t}))`\n",
        "          if bipartite,\n",
        "          edge indices :math:`(2, |\\mathcal{E}|)`,\n",
        "          edge features :math:`(|\\mathcal{E}|, D)` *(optional)*\n",
        "        - **output:** node features :math:`(|\\mathcal{V}|, H * F_{out})` or\n",
        "          :math:`((|\\mathcal{V}_t|, H * F_{out})` if bipartite.\n",
        "          If :obj:`return_attention_weights=True`, then\n",
        "          :math:`((|\\mathcal{V}|, H * F_{out}),\n",
        "          ((2, |\\mathcal{E}|), (|\\mathcal{E}|, H)))`\n",
        "          or :math:`((|\\mathcal{V_t}|, H * F_{out}), ((2, |\\mathcal{E}|),\n",
        "          (|\\mathcal{E}|, H)))` if bipartite\n",
        "    \"\"\"\n",
        "    _alpha: OptTensor\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: Union[int, Tuple[int, int]],\n",
        "        out_channels: int,\n",
        "        message_operation,\n",
        "        heads: int = 1,\n",
        "        concat: bool = True,\n",
        "        negative_slope: float = 0.2,\n",
        "        dropout: float = 0.0,\n",
        "        add_self_loops: bool = True,\n",
        "        edge_dim: Optional[int] = None,\n",
        "        fill_value: Union[float, Tensor, str] = 'mean',\n",
        "        bias: bool = True,\n",
        "        share_weights: bool = False,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.message_operation = message_operation\n",
        "        self.heads = heads\n",
        "        self.concat = concat\n",
        "        self.negative_slope = negative_slope\n",
        "        self.dropout = dropout\n",
        "        self.add_self_loops = add_self_loops\n",
        "        self.edge_dim = edge_dim\n",
        "        self.fill_value = fill_value\n",
        "        self.share_weights = share_weights\n",
        "\n",
        "        if isinstance(in_channels, int):\n",
        "            self.lin_l = Linear(in_channels, heads * out_channels, bias=bias,\n",
        "                                weight_initializer='glorot')\n",
        "            if share_weights:\n",
        "                self.lin_r = self.lin_l\n",
        "            else:\n",
        "                self.lin_r = Linear(in_channels, heads * out_channels,\n",
        "                                    bias=bias, weight_initializer='glorot')\n",
        "        else:\n",
        "            self.lin_l = Linear(in_channels[0], heads * out_channels,\n",
        "                                bias=bias, weight_initializer='glorot')\n",
        "            if share_weights:\n",
        "                self.lin_r = self.lin_l\n",
        "            else:\n",
        "                self.lin_r = Linear(in_channels[1], heads * out_channels,\n",
        "                                    bias=bias, weight_initializer='glorot')\n",
        "\n",
        "        self.att = Parameter(torch.Tensor(1, heads, out_channels))\n",
        "\n",
        "        if edge_dim is not None:\n",
        "            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False,\n",
        "                                   weight_initializer='glorot')\n",
        "        else:\n",
        "            self.lin_edge = None\n",
        "\n",
        "        if bias and concat:\n",
        "            self.bias = Parameter(torch.Tensor(heads * out_channels))\n",
        "        elif bias and not concat:\n",
        "            self.bias = Parameter(torch.Tensor(out_channels))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        self._alpha = None\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin_l.reset_parameters()\n",
        "        self.lin_r.reset_parameters()\n",
        "        if self.lin_edge is not None:\n",
        "            self.lin_edge.reset_parameters()\n",
        "        glorot(self.att)\n",
        "        zeros(self.bias)\n",
        "\n",
        "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n",
        "                edge_attr: OptTensor = None,\n",
        "                return_attention_weights: bool = None):\n",
        "        # type: (Union[Tensor, PairTensor], Tensor, OptTensor, NoneType) -> Tensor  # noqa\n",
        "        # type: (Union[Tensor, PairTensor], SparseTensor, OptTensor, NoneType) -> Tensor  # noqa\n",
        "        # type: (Union[Tensor, PairTensor], Tensor, OptTensor, bool) -> Tuple[Tensor, Tuple[Tensor, Tensor]]  # noqa\n",
        "        # type: (Union[Tensor, PairTensor], SparseTensor, OptTensor, bool) -> Tuple[Tensor, SparseTensor]  # noqa\n",
        "        r\"\"\"\n",
        "        Args:\n",
        "            return_attention_weights (bool, optional): If set to :obj:`True`,\n",
        "                will additionally return the tuple\n",
        "                :obj:`(edge_index, attention_weights)`, holding the computed\n",
        "                attention weights for each edge. (default: :obj:`None`)\n",
        "        \"\"\"\n",
        "        H, C = self.heads, self.out_channels\n",
        "\n",
        "        x_l: OptTensor = None\n",
        "        x_r: OptTensor = None\n",
        "        if isinstance(x, Tensor):\n",
        "            assert x.dim() == 2\n",
        "            x_l = self.lin_l(x).view(-1, H, C)\n",
        "            if self.share_weights:\n",
        "                x_r = x_l\n",
        "            else:\n",
        "                x_r = self.lin_r(x).view(-1, H, C)\n",
        "        else:\n",
        "            x_l, x_r = x[0], x[1]\n",
        "            assert x[0].dim() == 2\n",
        "            x_l = self.lin_l(x_l).view(-1, H, C)\n",
        "            if x_r is not None:\n",
        "                x_r = self.lin_r(x_r).view(-1, H, C)\n",
        "\n",
        "        assert x_l is not None\n",
        "        assert x_r is not None\n",
        "\n",
        "        if self.add_self_loops:\n",
        "            if isinstance(edge_index, Tensor):\n",
        "                num_nodes = x_l.size(0)\n",
        "                if x_r is not None:\n",
        "                    num_nodes = min(num_nodes, x_r.size(0))\n",
        "                edge_index, edge_attr = remove_self_loops(\n",
        "                    edge_index, edge_attr)\n",
        "                edge_index, edge_attr = add_self_loops(\n",
        "                    edge_index, edge_attr, fill_value=self.fill_value,\n",
        "                    num_nodes=num_nodes)\n",
        "            elif isinstance(edge_index, SparseTensor):\n",
        "                if self.edge_dim is None:\n",
        "                    edge_index = torch_sparse.set_diag(edge_index)\n",
        "                else:\n",
        "                    raise NotImplementedError(\n",
        "                        \"The usage of 'edge_attr' and 'add_self_loops' \"\n",
        "                        \"simultaneously is currently not yet supported for \"\n",
        "                        \"'edge_index' in a 'SparseTensor' form\")\n",
        "\n",
        "        # propagate_type: (x: PairTensor, edge_attr: OptTensor)\n",
        "        out = self.propagate(edge_index, x=(x_l, x_r), edge_attr=edge_attr,\n",
        "                             size=None)\n",
        "\n",
        "        alpha = self._alpha\n",
        "        self._alpha = None\n",
        "\n",
        "        if self.concat:\n",
        "            out = out.view(-1, self.heads * self.out_channels)\n",
        "        else:\n",
        "            out = out.mean(dim=1)\n",
        "\n",
        "        if self.bias is not None:\n",
        "            out = out + self.bias\n",
        "\n",
        "        if isinstance(return_attention_weights, bool):\n",
        "            assert alpha is not None\n",
        "            if isinstance(edge_index, Tensor):\n",
        "                return out, (edge_index, alpha)\n",
        "            elif isinstance(edge_index, SparseTensor):\n",
        "                return out, edge_index.set_value(alpha, layout='coo')\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "    def message(self, x_j: Tensor, x_i: Tensor, edge_attr: OptTensor,\n",
        "                index: Tensor, ptr: OptTensor,\n",
        "                size_i: Optional[int]) -> Tensor:\n",
        "        \n",
        "        # Changed Code:\n",
        "        # x = x_i + x_j\n",
        "        x = self.message_operation(x_i, x_j)\n",
        "\n",
        "        if edge_attr is not None:\n",
        "            # Changed Code:\n",
        "            raise NotImplementedError\n",
        "            # if edge_attr.dim() == 1:\n",
        "            #     edge_attr = edge_attr.view(-1, 1)\n",
        "            # assert self.lin_edge is not None\n",
        "            # edge_attr = self.lin_edge(edge_attr)\n",
        "            # edge_attr = edge_attr.view(-1, self.heads, self.out_channels)\n",
        "            # x = x + edge_attr\n",
        "\n",
        "        x = F.leaky_relu(x, self.negative_slope)\n",
        "        alpha = (x * self.att).sum(dim=-1)\n",
        "        alpha = softmax(alpha, index, ptr, size_i)\n",
        "        self._alpha = alpha\n",
        "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
        "        return x_j * alpha.unsqueeze(-1)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
        "                f'{self.out_channels}, heads={self.heads})')"
      ],
      "metadata": {
        "id": "LZhiMKViz6Dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GATv2MessageOperation(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads, message_operation):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATv2ConvMessageOperation(in_channels, hidden_channels,\n",
        "                                      message_operation=message_operation,\n",
        "                                      heads=heads, dropout=0.3)\n",
        "        \n",
        "        self.conv2 = GATv2ConvMessageOperation(hidden_channels * heads, out_channels,\n",
        "                                      message_operation=message_operation,\n",
        "                                      heads=1, dropout=0.3)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=0.3, training=self.training)\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.3, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x"
      ],
      "metadata": {
        "id": "XcjWKUPr-E_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "_fu7LW_4B3VG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN"
      ],
      "metadata": {
        "id": "nrra6C3NB41o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUMBER_RUNS = 4\n",
        "for config in [\n",
        "  ([500, 16, 8, 3], 2, 1),\n",
        "  ([500, 32, 16, 3], 2, 1),\n",
        "  ([500, 64, 32, 3], 2, 1),\n",
        "  ([500, 256, 64, 3], 2, 1),        \n",
        "  ([500, 1024, 1024, 3], 2, 1),\n",
        "]:\n",
        "  print(f\"Config: {config[0]}\")\n",
        "  test_acc_sum = 0 \n",
        "  for _ in range(NUMBER_RUNS):\n",
        "    model = GCN(*config)\n",
        "    train(model)\n",
        "    test_acc_sum += test(model)\n",
        "  test_acc = test_acc_sum / NUMBER_RUNS\n",
        "  print(f\"Test Accuracy: {round(test_acc*100, 2)}\")\n",
        "  print(\"====\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUxdrpDer6dN",
        "outputId": "84cbf794-d710-4dcd-9a4b-e04ccf66872c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config: [500, 16, 8, 3]\n",
            "Test Accuracy: 75.8\n",
            "====\n",
            "Config: [500, 32, 16, 3]\n",
            "Test Accuracy: 74.75\n",
            "====\n",
            "Config: [500, 64, 32, 3]\n",
            "Test Accuracy: 75.05\n",
            "====\n",
            "Config: [500, 256, 64, 3]\n",
            "Test Accuracy: 75.02\n",
            "====\n",
            "Config: [500, 1024, 1024, 3]\n",
            "Test Accuracy: 75.2\n",
            "====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUMBER_RUNS = 4\n",
        "for config in [\n",
        "  ([500, 16, 3], 1, 1),\n",
        "  ([500, 16, 8, 3], 2, 1),\n",
        "  ([500, 32, 16, 8, 3], 3, 1),\n",
        "  ([500, 16, 8, 3], 1, 2),        \n",
        "  ([500, 32, 16, 8, 3], 2, 2),\n",
        "  ([500, 64, 32, 16, 8, 3], 3, 2),\n",
        "  ([500, 32, 16, 8, 3], 1, 3),        \n",
        "  ([500, 64, 32, 16, 8, 3], 2, 3),\n",
        "  ([500, 128, 64, 32, 16, 8, 3], 3, 3)\n",
        "]:\n",
        "  print(f\"Config: {config[0]}\")\n",
        "  test_acc_sum = 0 \n",
        "  for _ in range(NUMBER_RUNS):\n",
        "    model = GCN(*config)\n",
        "    train(model)\n",
        "    test_acc_sum += test(model)\n",
        "  test_acc = test_acc_sum / NUMBER_RUNS\n",
        "  print(f\"Test Accuracy: {round(test_acc*100, 2)}\")\n",
        "  print(\"====\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lel5evDmuVkk",
        "outputId": "602c554f-f219-4777-d438-08fe11387f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config: [500, 16, 3]\n",
            "Test Accuracy: 70.0\n",
            "====\n",
            "Config: [500, 16, 8, 3]\n",
            "Test Accuracy: 72.62\n",
            "====\n",
            "Config: [500, 32, 16, 8, 3]\n",
            "Test Accuracy: 75.95\n",
            "====\n",
            "Config: [500, 16, 8, 3]\n",
            "Test Accuracy: 49.5\n",
            "====\n",
            "Config: [500, 32, 16, 8, 3]\n",
            "Test Accuracy: 53.5\n",
            "====\n",
            "Config: [500, 64, 32, 16, 8, 3]\n",
            "Test Accuracy: 71.35\n",
            "====\n",
            "Config: [500, 32, 16, 8, 3]\n",
            "Test Accuracy: 41.42\n",
            "====\n",
            "Config: [500, 64, 32, 16, 8, 3]\n",
            "Test Accuracy: 57.3\n",
            "====\n",
            "Config: [500, 128, 64, 32, 16, 8, 3]\n",
            "Test Accuracy: 65.72\n",
            "====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAT"
      ],
      "metadata": {
        "id": "Wj78QH6cB60g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUMBER_RUNS = 4\n",
        "test_accs = []\n",
        "for heads in range(1, 11):\n",
        "  print(f\"heads = {heads}\", end=\"\")\n",
        "  test_acc_sum = 0\n",
        "  for _ in range(NUMBER_RUNS):\n",
        "    model = GAT(500, [64, 16], 3, heads)\n",
        "    train(model)\n",
        "    test_acc_sum += test(model)\n",
        "  test_acc = test_acc_sum / NUMBER_RUNS\n",
        "  print(f\"test accuracy = {test_acc}\")\n",
        "  test_accs.append(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fo5IWaNN_Vk",
        "outputId": "21cee4f5-a5ab-4f79-e144-3ce2ea89bb42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heads = 1test accuracy = 0.73225\n",
            "heads = 2test accuracy = 0.7235\n",
            "heads = 3test accuracy = 0.742\n",
            "heads = 4test accuracy = 0.74\n",
            "heads = 5test accuracy = 0.736\n",
            "heads = 6test accuracy = 0.7374999999999999\n",
            "heads = 7test accuracy = 0.73875\n",
            "heads = 8test accuracy = 0.72575\n",
            "heads = 9test accuracy = 0.73575\n",
            "heads = 10test accuracy = 0.73275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(range(1, 11), [t*100 for t in test_accs])\n",
        "plt.plot(range(1, 11), [t*100 for t in test_accs])\n",
        "\n",
        "plt.title(\"Test Accuracy for Differents Heads\")\n",
        "plt.xlabel(\"Heads\")\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "7cI8oVYXRJZ0",
        "outputId": "907510b0-6b48-4dd2-faa6-e37d885bdb86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc_sum = 0\n",
        "for _ in range(NUMBER_RUNS):\n",
        "  model = GATDynamicWeights(500, 32, 3, heads=3)\n",
        "  train(model)\n",
        "  test_acc_sum += test(model)\n",
        "test_acc = test_acc_sum / NUMBER_RUNS\n",
        "print(f\"test accuracy = {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXr4tmJhVHjN",
        "outputId": "6e0ebaf2-33e4-405a-eb13-9de6a0897d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy = 0.745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc_sum = 0\n",
        "for _ in range(NUMBER_RUNS):\n",
        "  model = GAT(500, [64, 16], 3, heads=3)\n",
        "  train(model)\n",
        "  test_acc_sum += test(model)\n",
        "test_acc = test_acc_sum / NUMBER_RUNS\n",
        "print(f\"test accuracy = {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm3MtkifXBcl",
        "outputId": "137d7e0f-e840-414d-e853-61ba7e6ccdfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy = 0.74075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAT v2"
      ],
      "metadata": {
        "id": "ax9Thb-5CdIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def torch_sum(a, b): return a+b"
      ],
      "metadata": {
        "id": "pMh-kpqlzTv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUMBER_RUNS = 4\n",
        "for message_operation in [torch_sum, torch.minimum, torch.maximum, torch.mul]:\n",
        "  print(f\"message_operation = {message_operation}\", end=\" \")\n",
        "  test_acc_sum = 0\n",
        "  for _ in range(NUMBER_RUNS):\n",
        "    model = GATv2MessageOperation(in_channels=500, hidden_channels=32,\n",
        "                                  out_channels=3, heads=3,\n",
        "                                  message_operation=message_operation)\n",
        "    train(model)\n",
        "    test_acc_sum += test(model)\n",
        "  \n",
        "  test_acc = test_acc_sum / NUMBER_RUNS\n",
        "  print(f\"test accuracy = {round(test_acc*100, 2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D29EQMRrv8CJ",
        "outputId": "138ca024-c318-4557-a061-31df4cf65302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "message_operation = <function torch_sum at 0x7f13a81ce670> test accuracy = 75.22\n",
            "message_operation = <built-in method minimum of type object at 0x7f1417a5f420> test accuracy = 74.55\n",
            "message_operation = <built-in method maximum of type object at 0x7f1417a5f420> test accuracy = 74.7\n",
            "message_operation = <built-in method mul of type object at 0x7f1417a5f420> test accuracy = 74.35\n"
          ]
        }
      ]
    }
  ]
}